# -*- coding: utf-8 -*-

import asyncio
import time
import sounddevice as sd
import numpy as np
from google.cloud import speech

# --- Google Cloud Speech-to-Text è¨­å®š ---
# â€» ä¸‹è¨˜ã®å€¤ã¯ç’°å¢ƒã«åˆã‚ã›ã¦å¤‰æ›´ã—ã¦ãã ã•ã„
# ä¾‹: "en-US" ã‚„ "ja-JP" ãªã©
LANGUAGE_CODE = "ja-JP"
SAMPLE_RATE = 16000  # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆï¼ˆ16kHzï¼‰
CHANNEL_NUMS = 1      # ãƒ¢ãƒãƒ©ãƒ«éŸ³å£°

class RealtimeTranscriptionStream:
    """Google Cloud Speech-to-Text ã‚’ä½¿ç”¨ã—ãŸãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ–‡å­—èµ·ã“ã—"""

    def __init__(self):
        """åˆæœŸåŒ–"""
        # éŸ³å£°æ¤œå‡ºã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.SILENCE_THRESHOLD = 0.01  # ç„¡éŸ³ã®é–¾å€¤ï¼ˆèª¿æ•´å¯èƒ½ï¼‰
        self.SILENCE_DURATION = 2.0    # ç„¡éŸ³ãŒç¶šãæ™‚é–“ï¼ˆç§’ï¼‰
        self.MIN_RECORDING_TIME = 1.0  # æœ€å°éŒ²éŸ³æ™‚é–“ï¼ˆç§’ï¼‰
        # éŸ³å£°æ¤œå‡ºç”¨ã®å¤‰æ•°
        self.is_speaking = False
        self.last_speech_time = 0
        self.recording_start_time = 0
        self.should_stop_recording = False
        # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’éåŒæœŸã«ã‚„ã‚Šå–ã‚Šã™ã‚‹ãŸã‚ã®ã‚­ãƒ¥ãƒ¼
        self.audio_queue = asyncio.Queue()

    def detect_speech(self, audio_data):
        """éŸ³å£°ã®æœ‰ç„¡ã‚’æ¤œå‡º"""
        rms = np.sqrt(np.mean(audio_data ** 2))
        current_time = time.time()
        if rms > self.SILENCE_THRESHOLD:
            if not self.is_speaking:
                self.is_speaking = True
                self.recording_start_time = current_time
                print("ğŸ¤ éŸ³å£°æ¤œå‡ºé–‹å§‹...")
            self.last_speech_time = current_time
        else:
            if self.is_speaking:
                silence_duration = current_time - self.last_speech_time
                recording_duration = current_time - self.recording_start_time
                if (recording_duration >= self.MIN_RECORDING_TIME and
                        silence_duration >= self.SILENCE_DURATION):
                    self.is_speaking = False
                    self.should_stop_recording = True
                    print("ğŸ›‘ éŸ³å£°æ¤œå‡ºçµ‚äº†...")

    async def write_chunks_to_queue(self):
        """ãƒã‚¤ã‚¯ã‹ã‚‰ã®éŸ³å£°å…¥åŠ›ã‚’å–å¾—ã—ã€ã‚­ãƒ¥ãƒ¼ã«æ›¸ãè¾¼ã‚€"""
        loop = asyncio.get_running_loop()
        def callback(indata, frames, time, status):
            if status:
                print(f"Sounddevice status: {status}")
            self.detect_speech(indata.flatten())
            
            # PCMãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›ã—ã¦ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ 
            pcm_data = (indata * 32767).astype(np.int16).tobytes()
            # åˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ã‹ã‚‰ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã®ã‚­ãƒ¥ãƒ¼ã«å®‰å…¨ã«è¿½åŠ 
            loop.call_soon_threadsafe(self.audio_queue.put_nowait, pcm_data)

        print("ğŸ™ï¸ éŸ³å£°å…¥åŠ›ã‚’é–‹å§‹ã—ã¾ã™ã€‚è©±ã—å§‹ã‚ã¦ãã ã•ã„...")
        with sd.InputStream(
            samplerate=SAMPLE_RATE,
            channels=CHANNEL_NUMS,
            dtype='float32',
            callback=callback
        ):
            while not self.should_stop_recording:
                await asyncio.sleep(0.1)
        # éŒ²éŸ³ãŒå®Œäº†ã—ãŸã‚‰ã€ã‚¹ãƒˆãƒªãƒ¼ãƒ ã®çµ‚äº†ã‚’ç¤ºã™ãŸã‚ã«Noneã‚’ã‚­ãƒ¥ãƒ¼ã«å…¥ã‚Œã‚‹
        loop.call_soon_threadsafe(self.audio_queue.put_nowait, None)
        print("âœ… éŒ²éŸ³å®Œäº†")

    async def stream_requests(self):
        """ã‚­ãƒ¥ãƒ¼ã‹ã‚‰éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã€Google Cloud APIã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹"""
        # æœ€åˆã«è¨­å®šæƒ…å ±ã‚’é€ä¿¡
        yield speech.StreamingRecognizeRequest(
            streaming_config=speech.StreamingRecognitionConfig(
                config=speech.RecognitionConfig(
                    encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
                    sample_rate_hertz=SAMPLE_RATE,
                    language_code=LANGUAGE_CODE,
                ),
                interim_results=False, # ä¸­é–“çµæœã¯è¡¨ç¤ºã—ãªã„
            )
        )
        while True:
            # ã‚­ãƒ¥ãƒ¼ã‹ã‚‰éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            chunk = await self.audio_queue.get()
            if chunk is None:
                # çµ‚äº†ã‚·ã‚°ãƒŠãƒ«ã‚’å—ã‘å–ã£ãŸã‚‰ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ã‚’çµ‚äº†
                break
            # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ãƒªã‚¯ã‚¨ã‚¹ãƒˆã¨ã—ã¦yield
            yield speech.StreamingRecognizeRequest(audio_content=chunk)

    async def realtime_transcribe(self):
        """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ–‡å­—èµ·ã“ã—ã®ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
        # çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
        self.is_speaking = False
        self.should_stop_recording = False
        self.last_speech_time = 0
        self.recording_start_time = 0
        # å¤ã„ãƒ‡ãƒ¼ã‚¿ãŒæ®‹ã‚‰ãªã„ã‚ˆã†ã«ã‚­ãƒ¥ãƒ¼ã‚’ã‚¯ãƒªã‚¢
        while not self.audio_queue.empty():
            self.audio_queue.get_nowait()

        client = speech.SpeechAsyncClient()
        requests = self.stream_requests()

        # ãƒã‚¤ã‚¯ã‹ã‚‰ã®éŸ³å£°å…¥åŠ›ã‚’ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¿ã‚¹ã‚¯ã¨ã—ã¦é–‹å§‹
        mic_task = asyncio.create_task(self.write_chunks_to_queue())

        transcript_parts = []
        try:
            responses = await client.streaming_recognize(requests=requests)

            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰æ–‡å­—èµ·ã“ã—çµæœã‚’æŠ½å‡º
            async for response in responses:
                if not response.results:
                    continue
                result = response.results[0]
                if not result.alternatives:
                    continue
                
                # interim_results=False ã®ãŸã‚ã€å¾—ã‚‰ã‚Œã‚‹çµæœã¯å¸¸ã«æœ€çµ‚çš„ãªã‚‚ã®
                transcript_parts.append(result.alternatives[0].transcript)

        except Exception as e:
            # NOTE: 5åˆ†å¾Œã«ã‚¨ãƒ©ãƒ¼ï¼ˆ400 Exceeded maximum allowed stream duration of 305 seconds.ï¼‰ãŒç™ºç”Ÿã—ã¦ã€ã“ã®å‡¦ç†ã«å…¥ã‚‹ã€‚
            print(f"æ–‡å­—èµ·ã“ã—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            return "ä½•ã‹æŒ¨æ‹¶ã‹é›‘è«‡ã‚’ã—ã¦ãã ã•ã„ï¼ˆè‡ªå·±ç´¹ä»‹, ã—ã‚ƒã¹ã‚Šã‹ã‘ã¦ã»ã—ã„ã¨ãŠé¡˜ã„ã™ã‚‹, æœ€è¿‘ã®ãƒˆãƒ¬ãƒ³ãƒ‰æƒ…å ±ã‚’ç´¹ä»‹ã™ã‚‹ãªã©ï¼‰"
        
        # ãƒã‚¤ã‚¯ã®ã‚¿ã‚¹ã‚¯ãŒå®Œäº†ã™ã‚‹ã®ã‚’å¾…ã¤
        await mic_task

        # å¸¸ã«æ–‡å­—åˆ—ã‚’è¿”ã™ï¼ˆçµæœãŒãªã„å ´åˆã¯ç©ºæ–‡å­—åˆ—ï¼‰
        return "".join(transcript_parts)


# --- ãƒ¡ã‚¤ãƒ³å‡¦ç†ï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰ ---
async def _test_transcription():
    """æ–‡å­—èµ·ã“ã—ã®ãƒ†ã‚¹ãƒˆ"""
    transcriber = RealtimeTranscriptionStream()
    while True:
        print("-" * 20)
        transcript = await transcriber.realtime_transcribe()
        if transcript:
            print(f"âœ… èªè­˜çµæœ: {transcript}")
        else:
            print("éŸ³å£°ãŒèªè­˜ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
        
        # 'çµ‚äº†'ã¨ç™ºè©±ã•ã‚ŒãŸã‚‰ãƒ†ã‚¹ãƒˆã‚’çµ‚äº†
        if transcript == "çµ‚äº†":
            print("ãƒ†ã‚¹ãƒˆã‚’çµ‚äº†ã—ã¾ã™ã€‚")
            break

if __name__ == '__main__':
    print("ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ–‡å­—èµ·ã“ã—ã®ãƒ†ã‚¹ãƒˆã‚’é–‹å§‹ã—ã¾ã™ã€‚'çµ‚äº†'ã¨è©±ã™ã¨ãƒ—ãƒ­ã‚°ãƒ©ãƒ ãŒçµ‚äº†ã—ã¾ã™ã€‚")
    try:
        asyncio.run(_test_transcription())
    except KeyboardInterrupt:
        print("\nãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’å¼·åˆ¶çµ‚äº†ã—ã¾ã™ã€‚")
